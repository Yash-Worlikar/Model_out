{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bf4e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import ToTensor, Normalize , Compose\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61ef66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0883339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_set = np.memmap(r'F:\\Video_set\\All_data_set.npy',mode='r',shape=(8991,100,100,3))\n",
    "# x_np = torch.from_numpy(data_set)\n",
    "# x_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da36dc77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cbb5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = np.load(r'F:\\Video_set\\Sample_data_set.npy',mmap_mode=\"r+\")\n",
    "#data_set = np.load(r'F:\\Video100.npy')\n",
    "#np.random.shuffle(data_set)\n",
    "#data_set = data_set.memmap.astype(float)\n",
    "x_np = torch.from_numpy(data_set)\n",
    "x_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c5dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np.shape\n",
    "x_np.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1a9d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089232ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586266ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img = x_np.reshape((849,60,100,100,3))\n",
    "#x_img = x_np.reshape((99,60,100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52ab10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_np = x_np.permute(0,3,2,1)\n",
    "a = x_np.numpy()\n",
    "img = a\n",
    "img.shape\n",
    "plt.imshow(img[21323])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80ddd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img[1,2].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaf0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_img[1,40]\n",
    "img.shape\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f32cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_size = 100\n",
    "batch_size = 1\n",
    "stats = 1/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3934473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np[0].type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a7e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_np = x_np.memmap.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a68fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_np = x_np.float()\n",
    "# x_np = x_np/255\n",
    "# x_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = x_np.permute(0,3,1,2)\n",
    "x_img = x_np.reshape((849,3,60,100,100))\n",
    "x_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262040e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dc14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4826ac9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a3d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_set = DataLoader(x_img,batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03104922",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6725d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3989c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(img_tensors):\n",
    "    out = img_tensors\n",
    "    return out.clamp(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e500541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, nmax=60):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(make_grid(images.detach()[:nmax], nrow=10).permute(1,2,0))\n",
    "\n",
    "def show_batch(dl, nmax=60):\n",
    "    for image in dl:\n",
    "        for images in image:\n",
    "            images = images.reshape(60,3,100,100)\n",
    "            show_images(images, nmax)\n",
    "            print(images.shape)\n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bedd711",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(x_data_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6224ee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c407d790",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc855f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_set = DeviceDataLoader(x_data_set, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bef5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e7ab9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d240c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = nn.Sequential(\n",
    "    #in: 3 x 60 x 100 x 100 \n",
    "    nn.Conv3d(3, 64, kernel_size=(4,5,5), stride=(2,5,5), padding=1, bias=False),\n",
    "    nn.BatchNorm3d(64),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out 64 x 30 x 50 x 50\n",
    "    nn.Conv3d(64, 128, kernel_size=(4,4,4), stride=(2,2,2), padding=1, bias=False),\n",
    "    nn.BatchNorm3d(128),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # 128 x 25 x 25\n",
    "    nn.Conv3d(128, 256, kernel_size=(4,4,4), stride=(2,2,2), padding=1, bias=False),\n",
    "    nn.BatchNorm3d(256),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out: 256 x 8 x 8\n",
    "\n",
    "    nn.Conv3d(256, 512, kernel_size=(4,4,4), stride=(2,2,2), padding=1, bias=False),\n",
    "    nn.BatchNorm3d(512),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out: 512 x 4 x 4\n",
    "\n",
    "    nn.Conv3d(512, 1, kernel_size=(3,2,2), stride=1, padding=0, bias=False),\n",
    "    # out: 1 x 1 x 1\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Sigmoid())\n",
    "discriminator = to_device(discriminator, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83197f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator = nn.Sequential(\n",
    "#     #in: 3 x 60 x 100 x 100 \n",
    "#     nn.Conv3d(3, 64, kernel_size=(4,5,5), stride=2, padding=1, bias=False),\n",
    "#     nn.BatchNorm3d(64),\n",
    "#     nn.LeakyReLU(0.2, inplace=True),\n",
    "#     # out 64 x 30 x 50 x 50\n",
    "#     nn.Conv3d(64, 128, kernel_size=(4,4,4), stride=2, padding=1, bias=False),\n",
    "#     nn.BatchNorm3d(128),\n",
    "#     nn.LeakyReLU(0.2, inplace=True),\n",
    "#     # 128 x 25 x 25\n",
    "#     nn.Conv3d(128, 256, kernel_size=(3,4,4), stride=2, padding=1, bias=False),\n",
    "#     nn.BatchNorm3d(256),\n",
    "#     nn.LeakyReLU(0.2, inplace=True),\n",
    "#     # out: 256 x 8 x 8\n",
    "\n",
    "#     nn.Conv3d(256, 512, kernel_size=(4,4,4), stride=1, padding=1, bias=False),\n",
    "#     nn.BatchNorm3d(512),\n",
    "#     nn.LeakyReLU(0.2, inplace=True),\n",
    "#     # out: 512 x 4 x 4\n",
    "\n",
    "#     nn.Conv3d(512, 1, kernel_size=(4,4,4), stride=1, padding=0, bias=False),\n",
    "#     # out: 1 x 1 x 1\n",
    "\n",
    "#     nn.Flatten(),\n",
    "#     nn.Sigmoid())\n",
    "# discriminator = to_device(discriminator, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90d8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator = nn.Sequential(\n",
    "#     nn.Conv3d(3, 128, kernel_size=(4,4,4), stride=4, padding=0, bias=False),\n",
    "#     nn.BatchNorm3d(128),\n",
    "#     nn.LeakyReLU(0.2, inplace=True),\n",
    "    \n",
    "#     nn.Conv3d(128, 256, kernel_size=(5,5,5), stride=4, padding=1, bias=False),\n",
    "#     nn.BatchNorm3d(256),\n",
    "#     nn.LeakyReLU(0.2, inplace=True),\n",
    "#     nn.Conv3d(256, 512, kernel_size=(4,6,6), stride=1, padding=1, bias=False),\n",
    "#     nn.BatchNorm3d(512),\n",
    "#     nn.LeakyReLU(0.2, inplace=True),\n",
    "#     # out: 512 x 4 x 4\n",
    "#     nn.ConvTranspose3d(512, 60, kernel_size=(4,4,4), stride=1, padding=(0,0,0), bias=False),\n",
    "#     nn.Flatten(),\n",
    "#     nn.Sigmoid())\n",
    "# discriminator = to_device(discriminator, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f908b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b0b031",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generator = nn.Sequential(\n",
    "    #input 3x100x100\n",
    "#     nn.Conv3d(3,64,kernel_size=(3,3,3),bias=False),\n",
    "#     nn.BatchNorm2d(64),\n",
    "#     nn.ReLU(True),\n",
    "    \n",
    "#     nn.Conv3d(64,128,kernel_size=(3,3,3),bias=False),\n",
    "#     nn.BatchNorm2d(128),\n",
    "#     nn.ReLU(True),\n",
    "#     nn.Conv3d(128,512,kernel_size=(3,3,3),bias=False),\n",
    "#     nn.BatchNorm2d(512),\n",
    "#     nn.ReLU(True),\n",
    "    nn.Conv3d(3, 128, kernel_size=(4,4,4), stride=4, padding=0, bias=False),\n",
    "    nn.BatchNorm3d(128),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    \n",
    "    nn.Conv3d(128, 256, kernel_size=(5,5,5), stride=4, padding=1, bias=False),\n",
    "    nn.BatchNorm3d(256),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    nn.Conv3d(256, 512, kernel_size=(4,6,6), stride=1, padding=1, bias=False),\n",
    "    nn.BatchNorm3d(512),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out: 512 x 4 x 4\n",
    "    nn.ConvTranspose3d(512, 60, kernel_size=(4,4,4), stride=1, padding=(0,0,0), bias=False),\n",
    "\n",
    "\n",
    "    nn.ConvTranspose3d(60, 256, kernel_size=(5,5,5), stride=2, padding=(0,1,1), bias=False),\n",
    "    nn.BatchNorm3d(256),\n",
    "    nn.ReLU(True),\n",
    "    \n",
    "    nn.ConvTranspose3d(256, 128, kernel_size=(4,4,4), stride=2, padding=(0,1,1), bias=False),\n",
    "    nn.BatchNorm3d(128),\n",
    "    nn.ReLU(True),\n",
    "\n",
    "    nn.ConvTranspose3d(128, 64, kernel_size=(4,4,4), stride=(1,2,2), padding=(1,1,1), bias=False),\n",
    "    nn.BatchNorm3d(64),\n",
    "    nn.ReLU(True),\n",
    "    nn.ConvTranspose3d(64, 3, kernel_size=(4,4,4), stride=2, padding=(4,3,3), bias=False),\n",
    "    nn.Tanh()    \n",
    "    \n",
    ")\n",
    "#xb = torch.randn(60, latent_size, 1, 1) # random latent tensors\n",
    "\n",
    "xb = torch.unsqueeze(x_img[0],0)\n",
    "fake_images = generator(xb.float())\n",
    "fake_images.shape\n",
    "#show_images(denorm(fake_images))\n",
    "#print(fake_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01204147",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d72f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator = to_device(generator, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3052ded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = torch.unsqueeze(x_img[1],0)\n",
    "#xb = x_img\n",
    "x_img[0].shape\n",
    "fake_images = generator(xb.float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30809ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fake_images[0].shape\n",
    "fake_images.shape\n",
    "fake_images = fake_images.reshape(1,60,3,100,100)\n",
    "show_images(denorm(fake_images[0]))\n",
    "print(fake_images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d904f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14c4efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = nn.Sequential(\n",
    "#     #input 3x100x100\n",
    "# #     nn.Conv3d(3,64,kernel_size=(3,3,3),bias=False),\n",
    "# #     nn.BatchNorm2d(64),\n",
    "# #     nn.ReLU(True),\n",
    "    \n",
    "# #     nn.Conv3d(64,128,kernel_size=(3,3,3),bias=False),\n",
    "# #     nn.BatchNorm2d(128),\n",
    "# #     nn.ReLU(True),\n",
    "# #     nn.Conv3d(128,512,kernel_size=(3,3,3),bias=False),\n",
    "# #     nn.BatchNorm2d(512),\n",
    "# #     nn.ReLU(True),\n",
    "#     nn.Conv3d(3, 64, kernel_size=[2,4,4],stride=[1,1,1], padding=[3,1,1],bias=False),\n",
    "#     nn.BatchNorm2d(64),\n",
    "#     nn.LeakyReLU(0.2, inplace=True),\n",
    "#     # out 64x 50 x 50\n",
    "#     nn.Conv3d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#     nn.BatchNorm2d(128),\n",
    "#     nn.LeakyReLU(0.2, inplace=True),\n",
    "#     # 128 x 25 x 25\n",
    "#     nn.Conv3d(128, 256, kernel_size=4, stride=5, padding=1, bias=False),\n",
    "#     nn.BatchNorm2d(256),\n",
    "#     nn.LeakyReLU(0.2, inplace=True),\n",
    "#     # out: 256 x 8 x 8\n",
    "#     nn.Conv3d(256, 512, kernel_size=4, stride=1, padding=1, bias=False),\n",
    "#     nn.BatchNorm2d(512),\n",
    "#     nn.LeakyReLU(0.2, inplace=True),\n",
    "#     # out: 512 x 4 x 4\n",
    "#     nn.Conv3d(512, 60, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "\n",
    "\n",
    "#     nn.ConvTranspose3d(60, 256, kernel_size=(5,5,5), stride=2, padding=1, bias=False),\n",
    "#     nn.BatchNorm2d(121),\n",
    "#     nn.ReLU(True),\n",
    "    \n",
    "#     nn.ConvTranspose3d(256, 128, kernel_size=(4,4,4), stride=2, padding=0, bias=False),\n",
    "#     nn.BatchNorm2d(244),\n",
    "#     nn.ReLU(True),\n",
    "\n",
    "#     nn.ConvTranspose3d(128, 64, kernel_size=(4,4,4), stride=2, padding=0, bias=False),\n",
    "#     nn.BatchNorm2d(490 ),\n",
    "#     nn.ReLU(True),\n",
    "#     nn.ConvTranspose3d(64, 3, kernel_size=(4,4,4), stride=2, padding=1, bias=False),\n",
    "#     nn.Tanh()    \n",
    "    \n",
    "# )\n",
    "# #xb = torch.randn(60, latent_size, 1, 1) # random latent tensors\n",
    "# xb = x_img[0]\n",
    "# fake_images = generator(xb.float())\n",
    "# #show_images(denorm(fake_images))\n",
    "# print(fake_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7705e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = nn.Sequential(\n",
    "#     # in: latent_size x 1 x 1\n",
    "\n",
    "#     nn.ConvTranspose2d(latent_size, 512, kernel_size=5, stride=1, padding=0, bias=False),\n",
    "#     nn.BatchNorm2d(512),\n",
    "#     nn.ReLU(True),\n",
    "#     # out: 512 x 5 x 5\n",
    "\n",
    "#     nn.ConvTranspose2d(512, 256, kernel_size=5, stride=2, padding=1, bias=False),\n",
    "#     nn.BatchNorm2d(256),\n",
    "#     nn.ReLU(True),\n",
    "    \n",
    "#     nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=0, bias=False),\n",
    "#     nn.BatchNorm2d(128),\n",
    "#     nn.ReLU(True),\n",
    "\n",
    "#     nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=0, bias=False),\n",
    "#     nn.BatchNorm2d(64),\n",
    "#     nn.ReLU(True),\n",
    "#     nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "#     nn.Tanh()\n",
    "# )\n",
    "# xb = torch.randn(60, latent_size, 1, 1) # random latent tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92be486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b97587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(real_images, opt_d):\n",
    "    # Clear discriminator gradients\n",
    "    opt_d.zero_grad()\n",
    "    # Pass real images through discriminator\n",
    "    real_preds = discriminator(real_images)\n",
    "    real_targets = torch.ones(real_images.size(0), 1, device=device)\n",
    "    real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
    "    real_score = torch.mean(real_preds).item()\n",
    "    \n",
    "    # Generate fake images\n",
    "    #latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "    fake_images = generator(torch.unsqueeze(real_images[0],0))\n",
    "\n",
    "    # Pass fake images through discriminator\n",
    "    fake_targets = torch.zeros(fake_images.size(0), 1, device=device)\n",
    "    fake_preds = discriminator(fake_images)\n",
    "    fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
    "    fake_score = torch.mean(fake_preds).item()\n",
    "\n",
    "    # Update discriminator weights\n",
    "    loss = real_loss + fake_loss\n",
    "    loss.backward()\n",
    "    opt_d.step()\n",
    "    return loss.item(), real_score, fake_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7917f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(real_images,opt_g):\n",
    "    # Clear generator gradients\n",
    "    opt_g.zero_grad()\n",
    "    \n",
    "    # Generate fake images\n",
    "#     latent = torch.randn(batch_size, latent_size, 1, 1, device=device)\n",
    "#     fake_images = generator(latent)\n",
    "    fake_images = generator(torch.unsqueeze(real_images,0))\n",
    "    # Try to fool the discriminator\n",
    "    preds = discriminator(fake_images)\n",
    "    targets = torch.ones(batch_size, 1, device=device)\n",
    "    loss = F.binary_cross_entropy(preds, targets)\n",
    "    \n",
    "    # Update generator weights\n",
    "    loss.backward()\n",
    "    opt_g.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4840f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101cec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "sample_dir = 'generated'\n",
    "os.makedirs(sample_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1a11ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_samples(index, latent_tensors, show=True):\n",
    "    fake_images = generator(latent_tensors.float())\n",
    "    fake_images = fake_images.reshape(1,60,3,100,100)\n",
    "    print(fake_images[0].shape)\n",
    "\n",
    "    fake_images = denorm(fake_images)\n",
    "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
    "    save_image(fake_images[0], os.path.join(sample_dir, fake_fname), nrow=10)\n",
    "    print('Saving', fake_fname)\n",
    "    if show:\n",
    "        for image in fake_images:\n",
    "            fig, ax = plt.subplots(figsize=(10, 10))\n",
    "            ax.set_xticks([]); ax.set_yticks([])\n",
    "            fake_images.shape\n",
    "            ax.imshow(make_grid(image.cpu().detach(), nrow=10).permute(1, 2, 0))\n",
    "#         #ax.imshow(make_grid(denomrfake_images.cpu().detach(), nrow=6).permute(2, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f3156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed_latent = torch.randn(60, latent_size, 1, 1, device=device)\n",
    "# save_samples(0, fixed_latent)\n",
    "fake_images = torch.unsqueeze(x_img[20],0)\n",
    "fake_images.shape\n",
    "fake_images = fake_images.reshape(1,3,60,100,100)\n",
    "generator = to_device(generator, 'cpu')\n",
    "save_samples(0,fake_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c55b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de20eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a17a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = to_device(generator, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b9d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, start_idx=1):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Losses & scores\n",
    "    losses_g = []\n",
    "    losses_d = []\n",
    "    real_scores = []\n",
    "    fake_scores = []\n",
    "    \n",
    "    # Create optimizers\n",
    "    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.9))\n",
    "    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.9))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for real_images in tqdm(x_data_set):\n",
    "            # Train discriminator\n",
    "            real_images = real_images.float()\n",
    "            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n",
    "            # Train generator\n",
    "            loss_g = train_generator(real_images[0],opt_g)\n",
    "            \n",
    "        # Record losses & scores\n",
    "        losses_g.append(loss_g)\n",
    "        losses_d.append(loss_d)\n",
    "        real_scores.append(real_score)\n",
    "        fake_scores.append(fake_score)\n",
    "        \n",
    "        # Log losses & scores (last batch)\n",
    "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
    "            epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
    "    \n",
    "        # Save generated images\n",
    "        save_samples(epoch+start_idx, torch.unsqueeze(real_images[0],0), show=False)\n",
    "    \n",
    "    return losses_g, losses_d, real_scores, fake_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83049c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0002\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb1fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fit(epochs, lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b9d784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eb24a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcb9cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model checkpoints \n",
    "# torch.save(generator.state_dict(), 'generated/G.pth')\n",
    "# torch.save(discriminator.state_dict(), 'generated/D.pth')\n",
    "torch.save(generator, 'generated/Gen.pth')\n",
    "torch.save(discriminator, 'generated/Dis.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e4caae",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_g, losses_d, real_scores, fake_scores = history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7aa517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b509d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = to_device(generator,'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf416b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_images = generator()\n",
    "# show_images(denorm(fake_images))\n",
    "# print(fake_images.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
